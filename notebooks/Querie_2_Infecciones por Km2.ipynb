{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $file.common\n",
    "import spark._\n",
    "import common._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "import spark.sqlContext.implicits._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructType}\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.types._, func._\n",
    "import org.apache.spark.sql.functions.{col, to_date}\n",
    "import plotly._\n",
    "import plotly.element._\n",
    "import plotly.layout._\n",
    "import plotly.Almond._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Media de infecciones por Km2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infections(lines : RDD[String]) : RDD[Infection] =\n",
    "    lines.map(line => {\n",
    "      val arr = line.split(\",\")\n",
    "      Infection(\n",
    "        day = arr(1).toInt,\n",
    "        month = arr(2).toInt,\n",
    "        year = arr(3).toInt,\n",
    "        nCases = arr(4).toInt,\n",
    "        nDeaths = arr(5).toInt,\n",
    "        country = arr(6),\n",
    "        continent = arr(10)\n",
    "      )\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infectionRDD = infections(spark.sparkContext.textFile(\"../datasets/data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org.apache.spark.sql.catalyst.encoders.OuterScopes.addOuterScope(this)\n",
    "case class Population(\n",
    "    country : String, \n",
    "    population : Int, \n",
    "    density : Int, \n",
    "    land_area: Int, \n",
    "    ) \n",
    "extends Serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val populationData = spark.sparkContext.textFile(\"../datasets/population_by_country_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val header = populationData.first() \n",
    "\n",
    "def population(lines : RDD[String]) : RDD[Population] =\n",
    "    lines.filter(x => x != header)\n",
    "    .map(line => {\n",
    "      val arr = line.split(\",\")\n",
    "      Population(\n",
    "        country = arr(0),\n",
    "        population = arr(1).toInt,\n",
    "        density = arr(4).toInt,\n",
    "        land_area = arr(5).toInt,\n",
    "      )\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val populationRDD = population(populationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un join computacionalmente pesado desde el principio ya que cruza todos los datos sin quedarnos con los que nos interesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark no me deja hacer un Join de RDD que no sean pair RDD así que tenemos que construirlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// populationRDD.join(infectionRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyo Pair RDDs conservando todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val populationByCountry = populationRDD.map(\n",
    "    x => (x.country,x))\n",
    "\n",
    "val infectionByCountry = \n",
    "      infectionRDD.map(x => (x.country,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago el Join y agrupo por paises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val joinedRDD = infectionByCountry.join(populationByCountry).groupByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente calculo la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedRDD.mapValues(\n",
    "    x => x.map( \n",
    "        line => line._1.nCases.toFloat / line._2.land_area.toFloat\n",
    "    )).mapValues(\n",
    "    x => x.sum / x.size\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo hago todo en una única operación para calcular el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val notOptimizedRDD =\n",
    "    infectionByCountry.join(populationByCountry)\n",
    "    .groupByKey()\n",
    "    .mapValues(\n",
    "    x => x.map( \n",
    "        line => line._1.nCases.toFloat / line._2.land_area.toFloat)\n",
    "    ).mapValues(\n",
    "        x => x.sum / x.size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para optimizar un poco esta consulta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despejo solo los datos que me interesan para trabajar con Pair RDDs y optimizar la consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val countriesAndLandArea = populationRDD.map(\n",
    "    x => (x.country,x.land_area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val countriesAndCases = \n",
    "      infectionRDD.map(x => (x.country,x.nCases))\n",
    "      .groupByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuto un join y trabajo para calcular primero la media de infecciones por Km2 diaria, \n",
    "para luego calcular la media total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val average = countriesAndCases.join(countriesAndLandArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average.mapValues(\n",
    "    x => x._1.map(\n",
    "        y => (y.toFloat / x._2.toFloat)\n",
    "    )).mapValues(\n",
    "    x => x.sum/x.size\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo hago todo en una única operación para calcular el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val meanInfectionsRDD =\n",
    "countriesAndCases.join(countriesAndLandArea)   \n",
    ".mapValues(\n",
    "    x => x._1.map(\n",
    "        y => (y.toDouble / x._2.toDouble)\n",
    "    )).mapValues(\n",
    "    x => x.sum / x.size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.cern.sparkmeasure.StageMetrics(spark).runAndMeasure(\n",
    "    meanInfectionsRDD.collect\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta con DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infectionDS = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".csv(\"../datasets/covidworldwide.csv\")\n",
    ".withColumnRenamed(\"countriesAndTerritories\",\"Country\")\n",
    ".as[(String,String,String,String,Double,Double,String,String,String,String,String,String)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val populationDS = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".csv(\"../datasets/population_by_country_2020.csv\")\n",
    ".withColumnRenamed(\"Country (or dependency)\",\"Country\")\n",
    ".withColumnRenamed(\"Population (2020)\",\"Population\")\n",
    ".as[(String,Float,String,Float,Float,Float,Double,String,String,String,String)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val meanInfectionsperKM2DS = \n",
    "infectionDS.join(populationDS, \"Country\")\n",
    "        .select($\"Country\",\n",
    "                $\"dateRep\" as \"date\",\n",
    "                $\"cases\",\n",
    "                $\"Land Area (Km\\u00b2)\",\n",
    "                $\"cases\" / $\"Land Area (Km\\u00b2)\" as \"infection Per Km\\u00b2\")\n",
    "        .groupBy(\"Country\")\n",
    "        .agg(round(avg(\"infection Per Km\\u00b2\"),10).as[Float])\n",
    "        .orderBy(desc(\"round(avg(infection Per Km²), 10)\"))\n",
    "        .as[(String,Double)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.cern.sparkmeasure.StageMetrics(spark).runAndMeasure(meanInfectionsperKM2DS.collect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta con DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfCovid = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".csv(\"../datasets/covidworldwide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfPopulation = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".csv(\"../datasets/population_by_country_2020.csv\")\n",
    ".withColumnRenamed(\"Country (or dependency)\",\"Country\")\n",
    ".withColumnRenamed(\"Population (2020)\",\"Population\")\n",
    "dfPopulation.showHTML()\n",
    "dfPopulation.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifico los datos de entrada para que el formato fecha se adecue al TimeStamp de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfCovidClean = dfCovid\n",
    "    .select($\"*\",$\"dateRep\",translate($\"dateRep\",\"/\",\"-\").as(\"date\"))\n",
    "    .drop(\"dateRep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfCovidDate = dfCovidClean\n",
    "    .select($\"*\",col(\"date\"),to_date(col(\"date\"),\"dd-MM-yyyy\").as(\"to_date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago una consulta de prueba para obtener la media solo de los casos en España"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val spainCovid = dfCovid.select(\"dateRep\",\"cases\").where(\"countriesAndTerritories == 'Spain'\").toDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spainCovid.agg(avg(\"cases\")).showHTML()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente ejecuto la consulta de nuestro caso de uso, infecciones por Km2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val meanInfectionsperKM2DF = \n",
    "dfCovid.join(dfPopulation, $\"country\" === $\"countriesAndTerritories\")\n",
    "        .select($\"country\",\n",
    "                $\"dateRep\" as \"date\",\n",
    "                $\"cases\",\n",
    "                $\"Land Area (Km\\u00b2)\",\n",
    "                $\"cases\" / $\"Land Area (Km\\u00b2)\" as \"infection Per Km\\u00b2\")\n",
    "        .groupBy(\"country\")\n",
    "        .avg(\"infection Per Km\\u00b2\")\n",
    "        .orderBy(desc(\"avg(infection Per Km²)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.cern.sparkmeasure.StageMetrics(spark).runAndMeasure(\n",
    "    meanInfectionsperKM2DF.collect\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de datos con plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val (x,y) = meanInfectionsperKM2DF.collect.map(r=>(r(0).toString, r(1).toString.toFloat)).toList.unzip\n",
    "Bar(x, y).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de eficiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val (x, y) = Seq(\n",
    "    \"Not Optimized RDD\" -> runWithOutput(notOptimizedRDD.collect),\n",
    "    \"RDD\" -> runWithOutput(meanInfectionsRDD.collect),\n",
    "    \"DataSet\" -> runWithOutput(meanInfectionsperKM2DS.collect),\n",
    "    \"DataFrame\" -> runWithOutput(meanInfectionsperKM2DF.collect),\n",
    ").unzip\n",
    "\n",
    "Bar(x, y).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
