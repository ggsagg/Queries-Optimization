{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creamos la sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/sh/almond/almond-spark_2.12/0.9.1/almond-spark_2.12-0.9.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/2.4.5/spark-sql_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/almond-spark_2.12/0.9.1/almond-spark_2.12-0.9.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/2.4.5/spark-sql_2.12-2.4.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-parent_2.12/2.4.5/spark-parent_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-parent_2.12/2.4.5/spark-parent_2.12-2.4.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/apache/18/apache-18.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/apache/18/apache-18.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.6.7.3/jackson-databind-2.6.7.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.12/0.7.2/ammonite-spark_2.12-0.7.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/2.4.5/spark-catalyst_2.12-2.4.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/arrow/arrow-vector/0.10.0/arrow-vector-0.10.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/arrow/arrow-vector/0.10.0/arrow-vector-0.10.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.8/scala-library-2.12.8.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.8/scala-library-2.12.8.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/2.4.5/spark-catalyst_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.12/0.7.2/ammonite-spark_2.12-0.7.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.12/2.4.5/spark-sketch_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.6.7.3/jackson-databind-2.6.7.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/orc/orc-core/1.5.5/orc-core-1.5.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/univocity/univocity-parsers/2.7.3/univocity-parsers-2.7.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.5.5/orc-mapreduce-1.5.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.12/2.4.5/spark-sketch_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/orc/orc-core/1.5.5/orc-core-1.5.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/univocity/univocity-parsers/2.7.3/univocity-parsers-2.7.3.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.5.5/orc-mapreduce-1.5.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/parquet/parquet/1.10.1/parquet-1.10.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/xbean/xbean/4.8/xbean-4.8.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/arrow/arrow-java-root/0.10.0/arrow-java-root-0.10.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/orc/orc/1.5.5/orc-1.5.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/jackson-parent/2.6.2/jackson-parent-2.6.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/xbean/xbean/4.8/xbean-4.8.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/parquet/parquet/1.10.1/parquet-1.10.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/fasterxml/jackson/jackson-parent/2.6.2/jackson-parent-2.6.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/arrow/arrow-java-root/0.10.0/arrow-java-root-0.10.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/orc/orc/1.5.5/orc-1.5.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/fasterxml/oss-parent/24/oss-parent-24.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/apache/16/apache-16.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/geronimo/genesis/genesis-java5-flava/2.1/genesis-java5-flava-2.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/geronimo/genesis/genesis-java5-flava/2.1/genesis-java5-flava-2.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/apache/16/apache-16.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/fasterxml/oss-parent/24/oss-parent-24.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/geronimo/genesis/genesis-default-flava/2.1/genesis-default-flava-2.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/geronimo/genesis/genesis-default-flava/2.1/genesis-default-flava-2.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/geronimo/genesis/genesis/2.1/genesis-2.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/geronimo/genesis/genesis/2.1/genesis-2.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/apache/13/apache-13.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/apache/13/apache-13.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.7.9/jackson-core-2.7.9.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/codehaus/janino/janino/3.0.9/janino-3.0.9.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/twitter/chill-java/0.9.3/chill-java-0.9.3.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client/2.6.5/hadoop-client-2.6.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/codehaus/janino/janino/3.0.9/janino-3.0.9.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/3.0.9/commons-compiler-3.0.9.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/twitter/chill-java/0.9.3/chill-java-0.9.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.20.v20190813/jetty-server-9.4.20.v20190813.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client/2.6.5/hadoop-client-2.6.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/orc/orc-shims/1.5.5/orc-shims-1.5.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.pom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded https://repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/3.0.9/commons-compiler-3.0.9.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.20.v20190813/jetty-server-9.4.20.v20190813.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.7/antlr4-runtime-4.7.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.7.9/jackson-core-2.7.9.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/arrow/arrow-memory/0.10.0/arrow-memory-0.10.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/orc/orc-shims/1.5.5/orc-shims-1.5.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/avro/avro/1.8.2/avro-1.8.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.7/antlr4-runtime-4.7.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/arrow/arrow-memory/0.10.0/arrow-memory-0.10.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/avro/avro/1.8.2/avro-1.8.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.7.3/snappy-java-1.1.7.3.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.10/commons-codec-1.10.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/javax/activation/activation/1.1.1/activation-1.1.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.7.3/snappy-java-1.1.7.3.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/vlkan/flatbuffers/1.2.0-3f79e055/flatbuffers-1.2.0-3f79e055.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/arrow/arrow-format/0.10.0/arrow-format-0.10.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/netty/netty/3.9.9.Final/netty-3.9.9.Final.pom\n",
      "Downloaded https://repo1.maven.org/maven2/commons-codec/commons-codec/1.10/commons-codec-1.10.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/javax/activation/activation/1.1.1/activation-1.1.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/vlkan/flatbuffers/1.2.0-3f79e055/flatbuffers-1.2.0-3f79e055.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.16/slf4j-log4j12-1.7.16.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/arrow/arrow-format/0.10.0/arrow-format-0.10.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/netty/netty/3.9.9.Final/netty-3.9.9.Final.pom\n",
      "Downloading https://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.pom\n",
      "Downloaded https://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.16/slf4j-log4j12-1.7.16.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.pom\n",
      "Downloading https://repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.pom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded https://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/airlift/aircompressor/0.10/aircompressor-0.10.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.0/scala-parser-combinators_2.12-1.1.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/airlift/aircompressor/0.10/aircompressor-0.10.pom\n",
      "Downloaded https://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.6.7.1/jackson-module-scala_2.12-2.6.7.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/netty/netty-all/4.1.42.Final/netty-all-4.1.42.Final.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.0/scala-parser-combinators_2.12-1.1.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/net/razorvine/pyrolite/4.13/pyrolite-4.13.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.6.7.1/jackson-module-scala_2.12-2.6.7.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/net/razorvine/pyrolite/4.13/pyrolite-4.13.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/netty/netty-all/4.1.42.Final/netty-all-4.1.42.Final.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/codehaus/janino/janino-parent/3.0.9/janino-parent-3.0.9.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/apache/7/apache-7.pom\n",
      "Downloading https://repo1.maven.org/maven2/com/carrotsearch/hppc-parent/0.7.2/hppc-parent-0.7.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/curator/apache-curator/2.6.0/apache-curator-2.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/airlift/airbase/78/airbase-78.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/glassfish/jersey/project/2.22.2/project-2.22.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/apache/7/apache-7.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/commons/commons-parent/41/commons-parent-41.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/codehaus/janino/janino-parent/3.0.9/janino-parent-3.0.9.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/netty/netty-parent/4.1.42.Final/netty-parent-4.1.42.Final.pom\n",
      "Downloaded https://repo1.maven.org/maven2/com/carrotsearch/hppc-parent/0.7.2/hppc-parent-0.7.2.pom\n",
      "Downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-parent/3.1.5/metrics-parent-3.1.5.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/apache/curator/apache-curator/2.6.0/apache-curator-2.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/apache/avro/avro-parent/1.8.2/avro-parent-1.8.2.pom\n",
      "Downloaded https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-parent/3.1.5/metrics-parent-3.1.5.pom\n"
     ]
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.5` \n",
    "import $ivy.`sh.almond::almond-spark:0.6.0`\n",
    "\n",
    "import org.apache.spark.sql.{NotebookSparkSession, SparkSession}\n",
    "\n",
    "val spark: SparkSession = \n",
    "    NotebookSparkSession\n",
    "      .builder()\n",
    "      .appName(\"Queries Optimization\")\n",
    "      .master(\"local[*]\")\n",
    "      .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.slf4j.LoggerFactory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "import spark.sqlContext.implicits._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructType}\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.types._, func._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset ha sido obtenido de:\n",
    "https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide\n",
    "\n",
    "En el se observan los casos diarios de Covid-19 por país hasta el 14-12-20\n",
    "\n",
    "En la segunda parte se utilizan los datos de las medidas aplicadas a cada país por fecha de inicio y fin:\n",
    "\n",
    "https://www.ecdc.europa.eu/en/publications-data/download-data-response-measures-covid-19\n",
    "\n",
    "La última consulta para calcular las infecciones por km2:\n",
    "\n",
    "https://www.kaggle.com/tanuprabhu/population-by-country-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo una clase para trabajar con infecciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mInfection\u001b[39m"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Infection(day : Int, \n",
    "                     month : Int, \n",
    "                     year : Int, \n",
    "                     nCases: Int, \n",
    "                     nDeaths : Int, \n",
    "                     country : String,  \n",
    "                     continent : String) \n",
    "extends Serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y un método para medir tiempos de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run[A](code: => A): A = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val res = code\n",
    "    println(s\"Took ${System.currentTimeMillis() - start}\")\n",
    "    res\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empiezo trabajando con RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val readFromFile = spark.sparkContext.textFile(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una funcion para trabajar con un RDD de infecciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infections(lines : RDD[String]) : RDD[Infection] =\n",
    "    lines.map(line => {\n",
    "      val arr = line.split(\",\")\n",
    "      Infection(\n",
    "        day = arr(1).toInt,\n",
    "        month = arr(2).toInt,\n",
    "        year = arr(3).toInt,\n",
    "        nCases = arr(4).toInt,\n",
    "        nDeaths = arr(5).toInt,\n",
    "        country = arr(6),\n",
    "        continent = arr(10)\n",
    "      )\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo la media de infecciones diarias por país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def infectionGrowthAverage(infections : RDD[Infection]) : RDD[(String, Int)]= {\n",
    "\n",
    "    val countriesAndCases : RDD[(String, Iterable[Int])] = \n",
    "      infections.map(x => (x.country,x.nCases))\n",
    "      .groupByKey()\n",
    "      \n",
    "    countriesAndCases.mapValues(x => (x.sum / x.size)).sortBy(_._2)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestro el resultado y el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infectionRDD = infections(readFromFile)\n",
    "\n",
    "run(infectionGrowthAverage(infectionRDD))\n",
    ".foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hago los mismos calculos con un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierto el RDD obtenido previamente en un DataFrame para inferir la clase infección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infectionDF = spark.createDataFrame(infectionRDD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizo los métodos de la clase DF que incluye uno optimizado para calcular la media.\n",
    "\n",
    "Ejecuto y comprabamos como el tiempo de ejecución es significativamente menor que en RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(infectionDF.\n",
    "    groupBy(\"country\")\n",
    "    .avg(\"nCases\")\n",
    "    .orderBy(\"avg(nCases)\")\n",
    "    .count\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción es crear el DataFrame directamente importando los datos pero deja de ser un DF de infecciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfCovid = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".csv(\"covidworldwide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCovid.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCovid.explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(dfCovid.toDF.groupBy(\"countriesAndTerritories\")\n",
    "    .agg(mean(\"cases\")).orderBy(\"avg(cases)\")).show(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puedo definir el esquema manualmente para crear el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Defino el esquema manualmente pero podría verlo importando el csv y viendo como lo hace de base spark\n",
    "\n",
    "val schema = new StructType()\n",
    "    .add(\"dateRep\",StringType,true)\n",
    "    .add(\"day\",IntegerType,true)\n",
    "    .add(\"month\",IntegerType,true)\n",
    "    .add(\"year\",IntegerType,true)\n",
    "    .add(\"cases\",IntegerType,true)\n",
    "    .add(\"deaths\",IntegerType,true)\n",
    "    .add(\"countriesAndTerritories\",StringType,true)\n",
    "    .add(\"geoId\",StringType,true)\n",
    "    .add(\"countryterritoryCode\",StringType,true)\n",
    "    .add(\"popData2018\",IntegerType,true)\n",
    "    .add(\"continentExp\",StringType,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = spark.read\n",
    ".format(\"csv\")\n",
    ".option(\"header\",\"true\")\n",
    ".schema(schema)\n",
    ".load(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y con un DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infectionDS = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".csv(\"covidworldwide.csv\")\n",
    ".as[(String,String,String,String,String,String,String,String,String,String,String,String)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\n",
    "    infectionDS.groupBy($\"countriesAndTerritories\")\n",
    "    .agg(avg($\"cases\").as[Double])\n",
    "    .orderBy(\"avg(cases)\")\n",
    "    .count\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras opciones menos eficientes\n",
    "(Work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infectionDS.groupByKey(p => p._7) //hace shuffling de los datos\n",
    "        .mapValues(p => p._5.toDouble)\n",
    "        .mapGroups((k,vs) => (???))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infectionDS.groupByKey(p => p._7) //mas eficiente con el reduce\n",
    "        .mapValues(p => p._5.toDouble)\n",
    "        .reduceGroups((acc,str)=> ???)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infGrowAvg = new Aggregator[]{ //utilizando un Aggregator\n",
    "    \n",
    "}.toColumn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intento trabajar con DataSet de infecciones Dataset[Infection] pero falla \n",
    "(Work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos dará error pues no se pueden crear datasets sin tipo de datos y no entiende las infecciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infectionDS = spark.createDataset(infections(readFromFile)).as[Infection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val ds : Dataset[Infection] = spark.createDataset(infectionRDD).as[Infection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesito importar los Encoders y explicitar el tipo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.Encoders\n",
    "Encoders.product[Infection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.{Encoder, Encoders}\n",
    "import org.apache.spark.sql.Encoders\n",
    "\n",
    "val dataset = spark.createDataset(infectionRDD)(Encoders.product[Infection])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A partir de aquí intento crear un DataSet de infecciones pero siempre obtengo el mismo error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val infectionDS = spark.createDataset(infectionRDD).as[Infection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def infections(lines : Dataset[(String,String,String,String,String,String,String,String,String,String,String,String)]) \n",
    "                       : Dataset[Infection] = \n",
    "    lines.map(line => {\n",
    "      Infection(\n",
    "        day = line._1.toInt,\n",
    "        month = line._2.toInt,\n",
    "        year = line._3.toInt,\n",
    "        nCases = line._4.toInt,\n",
    "        nDeaths = line._5.toInt,\n",
    "        country = line._6,\n",
    "        continent = line._10\n",
    "      )\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infections(infectionDS).as[Infection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizo una segunda tabla y cruzo datos con RDD, DS y DF\n",
    "(De momento solo uso DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfMeasures = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".csv(\"response_graphs_data_2021-04-15.csv\")\n",
    "dfMeasures.show\n",
    "dfMeasures.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfPopulation = spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"charset\", \"UTF8\")\n",
    ".option(\"delimiter\",\",\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".csv(\"population_by_country_2020.csv\")\n",
    "dfPopulation.show\n",
    "dfPopulation.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifico los datos de entrada para que el formato fecha se adecue al TimeStamp de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfCovidClean = dfCovid.select($\"*\",$\"dateRep\",translate($\"dateRep\",\"/\",\"-\").as(\"new-date\")).drop(\"dateRep\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago una consulta de prueba para obtener la media solo de los casos en España"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val spainCovid = dfCovid.select(\"dateRep\",\"cases\").where(\"countriesAndTerritories == 'Spain'\").toDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(spainCovid.agg(avg(\"cases\"))).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cruzo los datos con un Join y hago algunas consultas sencillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val megaDF = dfCovid.join(dfMeasures, $\"Country\" === $\"countriesAndTerritories\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megaDF.select(\"cases\",\"deaths\",\"dateRep\",\"Response_measure\")\n",
    "    .where(\"countriesAndTerritories == 'Spain'\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(dfCovid.join(dsMeasures, $\"Country\" === $\"countriesAndTerritories\")\n",
    "        .select(\"cases\",\"deaths\",\"dateRep\",\"Response_measure\")\n",
    "        .where(\"countriesAndTerritories == 'Spain'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo una consulta para calcular la media de infecciones por Km2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\n",
    "dfCovid.join(dfPopulation, $\"Country (or dependency)\" === $\"countriesAndTerritories\")\n",
    "        .select($\"Country (or dependency)\" as \"Country\",\n",
    "                $\"dateRep\" as \"date\",\n",
    "                $\"cases\",\n",
    "                $\"Land Area (Km\\u00b2)\",\n",
    "                $\"cases\" / $\"Land Area (Km\\u00b2)\" as \"infection Per Km\\u00b2\")\n",
    "        .groupBy(\"Country\")\n",
    "        .avg(\"infection Per Km\\u00b2\")\n",
    "        .orderBy(asc(\"avg(infection Per Km²)\"))\n",
    "        .count\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas y observaciones personales interesantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCovid.select(\"dateRep\",\"countriesAndTerritories\",\"cases\").show //aplico los métodos de DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCovid.createOrReplaceTempView(\"covid\") //se pueden aplicar consultas SQL sobre DF\n",
    "\n",
    "spark.sql(\"SELECT * FROM covid WHERE countriesAndTerritories == 'Spain'\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//filtrados sobre dataframes\n",
    "dfCovid.filter($\"continentExp\" === \"Asia\" || $\"continentExp\" === \"Europe\").sort($\"continentExp\".asc).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
